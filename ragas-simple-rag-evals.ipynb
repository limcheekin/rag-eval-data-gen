{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09169c4",
   "metadata": {},
   "source": [
    "https://docs.ragas.io/en/stable/getstarted/rag_eval/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dfb4e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb018f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(\n",
    "                        model=os.getenv(\"GENERATOR_MODEL\"),\n",
    "                        api_key=os.getenv(\"GENERATOR_API_KEY\"),\n",
    "                        base_url=os.getenv(\"GENERATOR_BASE_URL\")\n",
    "                    )\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "                        model=os.getenv(\"EMBEDDER_MODEL\"),\n",
    "                        api_key=os.getenv(\"EMBEDDER_API_KEY\"),\n",
    "                        base_url=os.getenv(\"EMBEDDER_BASE_URL\")\n",
    "                    )\n",
    "        self.doc_embeddings = None\n",
    "        self.docs = None\n",
    "\n",
    "    def load_documents(self, documents):\n",
    "        \"\"\"Load documents and compute their embeddings.\"\"\"\n",
    "        self.docs = documents\n",
    "        self.doc_embeddings = self.embeddings.embed_documents(documents)\n",
    "\n",
    "    def get_most_relevant_docs(self, query):\n",
    "        \"\"\"Find the most relevant document for a given query.\"\"\"\n",
    "        if not self.docs or not self.doc_embeddings:\n",
    "            raise ValueError(\"Documents and their embeddings are not loaded.\")\n",
    "\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        similarities = [\n",
    "            np.dot(query_embedding, doc_emb)\n",
    "            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
    "            for doc_emb in self.doc_embeddings\n",
    "        ]\n",
    "        most_relevant_doc_index = np.argmax(similarities)\n",
    "        return [self.docs[most_relevant_doc_index]]\n",
    "\n",
    "    def generate_answer(self, query, relevant_doc):\n",
    "        \"\"\"Generate an answer for a given query based on the most relevant document.\"\"\"\n",
    "        prompt = f\"question: {query}\\n\\nDocuments: {relevant_doc}\"\n",
    "        messages = [\n",
    "            (\"system\", \"You are a helpful assistant that answers questions based on given documents only.\"),\n",
    "            (\"user\", prompt),\n",
    "        ]\n",
    "        ai_msg = self.llm.invoke(messages)\n",
    "        return ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98778ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"docs/\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae79dc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text Chunkers initialized.\n",
      "\n",
      "🔄 Chunking documents...\n",
      "👍 Documents split into 46 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"), \n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"####\", \"Header 4\"),\n",
    "    (\"#####\", \"Header 5\"),\n",
    "    (\"######\", \"Header 6\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    "    strip_headers=False,  # Keep headers in content for context\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    add_start_index=True,\n",
    ")\n",
    "print(\"✅ Text Chunkers initialized.\")\n",
    "\n",
    "print(\"\\n🔄 Chunking documents...\")\n",
    "md_split_docs = []\n",
    "for doc in docs:\n",
    "    md_header_splits = markdown_splitter.split_text(doc.page_content)\n",
    "    md_header_splits = text_splitter.split_documents(md_header_splits)\n",
    "    for split_chunk in md_header_splits:\n",
    "        md_split_docs.append(split_chunk.page_content)\n",
    "print(f\"👍 Documents split into {len(md_split_docs)} chunks.\")\n",
    "docs = md_split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0143db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《神奇之门: 奇门遁甲大解谜》  \n",
      "张志春著  \n",
      "上 编  \n",
      "易学思维中的科学性精华  \n",
      "第一章  \n",
      "易学的科学价值主要在思维科学  \n",
      "1. 易学的历史发展  \n",
      "起源与演变：从伏羲画八卦开始，历经夏《连山》、商《归藏》、周《周易》的成型，到孔子作\"十翼\"（易传），汉代列为群经之首，形成完整的易学体系。  \n",
      "流派分化：清代《四库全书》概括易学为\"两派六宗\"------象数派（含象数、机祥、图书）与义理派（含儒理、考史），两者长期争论并存，涵盖哲学、天文、军事等广泛领域。  \n",
      "2. 易学的现代研究  \n",
      "全球影响：近代以来，易学从中国走向世界，引发跨学科研究热潮，包括社会科学、自然科学的多元视角。  \n",
      "科学评价：中外学者（如邓拓、荣格、张协和）高度评价《周易》的智慧价值，认为其宇宙观与规律性研究对现代科学（如量子物理）有启发，甚至与诺贝尔奖成果相关。  \n",
      "3. 易学的科学价值争议  \n",
      "观点分歧：  \n",
      "部分人认为价值仅在\"易理\"（哲学），否定\"象数/数术\"的科学性；  \n",
      "另一派认为\"象数\"是易理的应用体现，两者不可割裂；  \n",
      "折中观点主张\"学\"（理论）与\"术\"（应用）结合，古为今用。  \n",
      "作者立场：支持第三种观点，强调象、数、理、占是统一整体，易学价值需从理论和应用两方面综合研究。  \n",
      "4. 易学的科学定位  \n",
      "思维科学为核心：作者引用钱学森的现代科学体系分类，提出易学应归入思维科学，因其提供了独特的认知模式（如辩证、象数思维），对自然科学、社会科学及人生实践均有指导意义。  \n",
      "实践价值：易学不仅包含哲学思想（基础科学层次），也通过数术技术（工程技术层次）联系实际，促进物质与精神文明发展。  \n",
      "5. 结论  \n",
      "易学作为中华文化的智慧总汇，其核心价值在于思维科学领域，兼具理论深度与实践意义，需以开放态度继承发展，服务于现代科学与文明建设。  \n",
      "第二章  \n",
      "人脑思维方式与易学的产生  \n",
      "1. 人类思维方式的分类  \n",
      "现代思维科学将人类思维方式分为三类：  \n",
      "逻辑思维（理性思维）：代表学科如数学、物理、化学。  \n",
      "形象思维（感性思维）：代表学科如文学、艺术、音乐。  \n",
      "灵感思维（感应思维/直觉思维）：代表学科如易学、佛学、心理学、气功。  \n",
      "人类思维发展的规律：  \n",
      "婴幼儿以感性思维为主，随着年龄增长，逻辑思维逐渐增强。\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d9bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 中国古代智慧，特别是易学，与现代科学思想有何关联？以具体的例子来证明这种关联。\n",
      "Relevant Document: ['《神奇之门: 奇门遁甲大解谜》  \\n张志春著  \\n上 编  \\n易学思维中的科学性精华  \\n第一章  \\n易学的科学价值主要在思维科学  \\n1. 易学的历史发展  \\n起源与演变：从伏羲画八卦开始，历经夏《连山》、商《归藏》、周《周易》的成型，到孔子作\"十翼\"（易传），汉代列为群经之首，形成完整的易学体系。  \\n流派分化：清代《四库全书》概括易学为\"两派六宗\"------象数派（含象数、机祥、图书）与义理派（含儒理、考史），两者长期争论并存，涵盖哲学、天文、军事等广泛领域。  \\n2. 易学的现代研究  \\n全球影响：近代以来，易学从中国走向世界，引发跨学科研究热潮，包括社会科学、自然科学的多元视角。  \\n科学评价：中外学者（如邓拓、荣格、张协和）高度评价《周易》的智慧价值，认为其宇宙观与规律性研究对现代科学（如量子物理）有启发，甚至与诺贝尔奖成果相关。  \\n3. 易学的科学价值争议  \\n观点分歧：  \\n部分人认为价值仅在\"易理\"（哲学），否定\"象数/数术\"的科学性；  \\n另一派认为\"象数\"是易理的应用体现，两者不可割裂；  \\n折中观点主张\"学\"（理论）与\"术\"（应用）结合，古为今用。  \\n作者立场：支持第三种观点，强调象、数、理、占是统一整体，易学价值需从理论和应用两方面综合研究。  \\n4. 易学的科学定位  \\n思维科学为核心：作者引用钱学森的现代科学体系分类，提出易学应归入思维科学，因其提供了独特的认知模式（如辩证、象数思维），对自然科学、社会科学及人生实践均有指导意义。  \\n实践价值：易学不仅包含哲学思想（基础科学层次），也通过数术技术（工程技术层次）联系实际，促进物质与精神文明发展。  \\n5. 结论  \\n易学作为中华文化的智慧总汇，其核心价值在于思维科学领域，兼具理论深度与实践意义，需以开放态度继承发展，服务于现代科学与文明建设。  \\n第二章  \\n人脑思维方式与易学的产生  \\n1. 人类思维方式的分类  \\n现代思维科学将人类思维方式分为三类：  \\n逻辑思维（理性思维）：代表学科如数学、物理、化学。  \\n形象思维（感性思维）：代表学科如文学、艺术、音乐。  \\n灵感思维（感应思维/直觉思维）：代表学科如易学、佛学、心理学、气功。  \\n人类思维发展的规律：  \\n婴幼儿以感性思维为主，随着年龄增长，逻辑思维逐渐增强。']\n",
      "Answer: 根据提供的文档，中国古代智慧，特别是易学，与现代科学思想的关联主要体现在其作为一种独特的**思维科学**，以及对现代科学的启发作用：\n",
      "\n",
      "1.  **作为“思维科学”的核心价值：** 文中指出，易学的科学价值主要体现在“思维科学”领域。钱学森将易学体系归入现代科学体系中的“思维科学”范畴。易学提供了一种独特的认知模式，如辩证思维和象数思维，对自然科学、社会科学乃至人生实践都具有指导意义。\n",
      "\n",
      "2.  **对现代科学的启发与关联：**\n",
      "    *   **启发量子物理：** 中外学者（如邓拓、荣格、张协和）高度评价《周易》的智慧价值，认为其“宇宙观与规律性研究”对**现代科学（如量子物理）**有启发。\n",
      "    *   **与诺贝尔奖成果相关：** 文中提到，易学的智慧价值“甚至与**诺贝尔奖成果**相关”。\n",
      "    *   **作为“灵感思维”的代表：** 现代思维科学将人类思维方式分为逻辑思维、形象思维和灵感思维。易学被归类为**灵感思维**（或称感应思维/直觉思维）的代表学科，与数学、物理等逻辑思维学科和文学艺术等形象思维学科并存，体现了人类思维方式的多元性和互补性。\n",
      "\n",
      "这些具体的例子表明，易学并非仅仅是哲学或迷信，而是以其独特的思维模式和对宇宙规律的探索，被认为能够启发和关联到现代科学的某些前沿领域。\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAG instance\n",
    "rag = RAG()\n",
    "\n",
    "# Load documents\n",
    "rag.load_documents(docs)\n",
    "\n",
    "# Query and retrieve the most relevant document\n",
    "query = \"中国古代智慧，特别是易学，与现代科学思想有何关联？以具体的例子来证明这种关联。\"\n",
    "relevant_doc = rag.get_most_relevant_docs(query)\n",
    "\n",
    "# Generate an answer\n",
    "answer = rag.generate_answer(query, relevant_doc)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Relevant Document: {relevant_doc}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2ef53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/limcheekin/My Passport/ws/py/rag-eval-data-gen/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(features=['user_input', 'retrieved_contexts', 'reference_contexts', 'response', 'reference'], len=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ragas.dataset_schema import EvaluationDataset\n",
    "\n",
    "df = pd.read_parquet(\"data/ragas_openai_testset.parquet\")\n",
    "df[\"retrieved_contexts\"] = df[\"reference_contexts\"]\n",
    "df[\"response\"] = df[\"reference\"]\n",
    "data_list = df.to_dict(orient=\"records\")\n",
    "evaluation_dataset = EvaluationDataset.from_list(data_list)\n",
    "evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783564a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  80%|████████  | 16/20 [00:55<00:13,  3.35s/it]Exception raised in Job[1]: TimeoutError()\n",
      "Evaluating:  85%|████████▌ | 17/20 [03:00<01:42, 34.30s/it]Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Evaluating:  95%|█████████▌| 19/20 [03:04<00:20, 20.78s/it]Exception raised in Job[19]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 20/20 [03:06<00:00,  9.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 1.0000, 'context_recall': 1.0000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(rag.llm)\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ContextPrecision, ContextRecall\n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,\n",
    "                  metrics=[\n",
    "                    #LLMContextRecall(), \n",
    "                    #Faithfulness(), \n",
    "                    #FactualCorrectness(),\n",
    "                    ContextPrecision(),\n",
    "                    ContextRecall()],\n",
    "                  llm=evaluator_llm\n",
    "                )\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d0bf2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwen3-embedding-0.6b'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv(\"EMBEDDER_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297076d",
   "metadata": {},
   "source": [
    "## Eval Results\n",
    "### Retriever \n",
    "- **snowflake-arctic-embed-l-v2.0**\n",
    "  - context_precision: 1.0000\n",
    "  - context_recall: 0.9500\n",
    "- **qwen3-embedding-0.6b**\n",
    "  - context_precision: 1.0000\n",
    "  - context_recall: 1.0000\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
