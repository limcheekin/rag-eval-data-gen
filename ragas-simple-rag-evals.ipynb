{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09169c4",
   "metadata": {},
   "source": [
    "https://docs.ragas.io/en/stable/getstarted/rag_eval/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dfb4e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffb018f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(\n",
    "                        model=os.getenv(\"GENERATOR_MODEL\"),\n",
    "                        api_key=os.getenv(\"GENERATOR_API_KEY\"),\n",
    "                        base_url=os.getenv(\"GENERATOR_BASE_URL\")\n",
    "                    )\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "                        model=os.getenv(\"EMBEDDER_MODEL\"),\n",
    "                        api_key=os.getenv(\"EMBEDDER_API_KEY\"),\n",
    "                        base_url=os.getenv(\"EMBEDDER_BASE_URL\")\n",
    "                    )\n",
    "        self.doc_embeddings = None\n",
    "        self.docs = None\n",
    "\n",
    "    def load_documents(self, documents):\n",
    "        \"\"\"Load documents and compute their embeddings.\"\"\"\n",
    "        self.docs = documents\n",
    "        self.doc_embeddings = self.embeddings.embed_documents(documents)\n",
    "\n",
    "    def get_most_relevant_docs(self, query):\n",
    "        \"\"\"Find the most relevant document for a given query.\"\"\"\n",
    "        if not self.docs or not self.doc_embeddings:\n",
    "            raise ValueError(\"Documents and their embeddings are not loaded.\")\n",
    "\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        similarities = [\n",
    "            np.dot(query_embedding, doc_emb)\n",
    "            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
    "            for doc_emb in self.doc_embeddings\n",
    "        ]\n",
    "        most_relevant_doc_index = np.argmax(similarities)\n",
    "        return [self.docs[most_relevant_doc_index]]\n",
    "\n",
    "    def generate_answer(self, query, relevant_doc):\n",
    "        \"\"\"Generate an answer for a given query based on the most relevant document.\"\"\"\n",
    "        prompt = f\"question: {query}\\n\\nDocuments: {relevant_doc}\"\n",
    "        messages = [\n",
    "            (\"system\", \"You are a helpful assistant that answers questions based on given documents only.\"),\n",
    "            (\"user\", prompt),\n",
    "        ]\n",
    "        ai_msg = self.llm.invoke(messages)\n",
    "        return ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98778ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"docs/\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae79dc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text Chunkers initialized.\n",
      "\n",
      "🔄 Chunking documents...\n",
      "👍 Documents split into 46 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"), \n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"####\", \"Header 4\"),\n",
    "    (\"#####\", \"Header 5\"),\n",
    "    (\"######\", \"Header 6\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    "    strip_headers=False,  # Keep headers in content for context\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    add_start_index=True,\n",
    ")\n",
    "print(\"✅ Text Chunkers initialized.\")\n",
    "\n",
    "print(\"\\n🔄 Chunking documents...\")\n",
    "md_split_docs = []\n",
    "for doc in docs:\n",
    "    md_header_splits = markdown_splitter.split_text(doc.page_content)\n",
    "    md_header_splits = text_splitter.split_documents(md_header_splits)\n",
    "    for split_chunk in md_header_splits:\n",
    "        md_split_docs.append(split_chunk.page_content)\n",
    "print(f\"👍 Documents split into {len(md_split_docs)} chunks.\")\n",
    "docs = md_split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0143db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《神奇之门: 奇门遁甲大解谜》  \n",
      "张志春著  \n",
      "上 编  \n",
      "易学思维中的科学性精华  \n",
      "第一章  \n",
      "易学的科学价值主要在思维科学  \n",
      "1. 易学的历史发展  \n",
      "起源与演变：从伏羲画八卦开始，历经夏《连山》、商《归藏》、周《周易》的成型，到孔子作\"十翼\"（易传），汉代列为群经之首，形成完整的易学体系。  \n",
      "流派分化：清代《四库全书》概括易学为\"两派六宗\"------象数派（含象数、机祥、图书）与义理派（含儒理、考史），两者长期争论并存，涵盖哲学、天文、军事等广泛领域。  \n",
      "2. 易学的现代研究  \n",
      "全球影响：近代以来，易学从中国走向世界，引发跨学科研究热潮，包括社会科学、自然科学的多元视角。  \n",
      "科学评价：中外学者（如邓拓、荣格、张协和）高度评价《周易》的智慧价值，认为其宇宙观与规律性研究对现代科学（如量子物理）有启发，甚至与诺贝尔奖成果相关。  \n",
      "3. 易学的科学价值争议  \n",
      "观点分歧：  \n",
      "部分人认为价值仅在\"易理\"（哲学），否定\"象数/数术\"的科学性；  \n",
      "另一派认为\"象数\"是易理的应用体现，两者不可割裂；  \n",
      "折中观点主张\"学\"（理论）与\"术\"（应用）结合，古为今用。  \n",
      "作者立场：支持第三种观点，强调象、数、理、占是统一整体，易学价值需从理论和应用两方面综合研究。  \n",
      "4. 易学的科学定位  \n",
      "思维科学为核心：作者引用钱学森的现代科学体系分类，提出易学应归入思维科学，因其提供了独特的认知模式（如辩证、象数思维），对自然科学、社会科学及人生实践均有指导意义。  \n",
      "实践价值：易学不仅包含哲学思想（基础科学层次），也通过数术技术（工程技术层次）联系实际，促进物质与精神文明发展。  \n",
      "5. 结论  \n",
      "易学作为中华文化的智慧总汇，其核心价值在于思维科学领域，兼具理论深度与实践意义，需以开放态度继承发展，服务于现代科学与文明建设。  \n",
      "第二章  \n",
      "人脑思维方式与易学的产生  \n",
      "1. 人类思维方式的分类  \n",
      "现代思维科学将人类思维方式分为三类：  \n",
      "逻辑思维（理性思维）：代表学科如数学、物理、化学。  \n",
      "形象思维（感性思维）：代表学科如文学、艺术、音乐。  \n",
      "灵感思维（感应思维/直觉思维）：代表学科如易学、佛学、心理学、气功。  \n",
      "人类思维发展的规律：  \n",
      "婴幼儿以感性思维为主，随着年龄增长，逻辑思维逐渐增强。\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48d9bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 中国古代智慧，特别是易学，与现代科学思想有何关联？以具体的例子来证明这种关联。\n",
      "Relevant Document: ['《神奇之门: 奇门遁甲大解谜》  \\n张志春著  \\n上 编  \\n易学思维中的科学性精华  \\n第一章  \\n易学的科学价值主要在思维科学  \\n1. 易学的历史发展  \\n起源与演变：从伏羲画八卦开始，历经夏《连山》、商《归藏》、周《周易》的成型，到孔子作\"十翼\"（易传），汉代列为群经之首，形成完整的易学体系。  \\n流派分化：清代《四库全书》概括易学为\"两派六宗\"------象数派（含象数、机祥、图书）与义理派（含儒理、考史），两者长期争论并存，涵盖哲学、天文、军事等广泛领域。  \\n2. 易学的现代研究  \\n全球影响：近代以来，易学从中国走向世界，引发跨学科研究热潮，包括社会科学、自然科学的多元视角。  \\n科学评价：中外学者（如邓拓、荣格、张协和）高度评价《周易》的智慧价值，认为其宇宙观与规律性研究对现代科学（如量子物理）有启发，甚至与诺贝尔奖成果相关。  \\n3. 易学的科学价值争议  \\n观点分歧：  \\n部分人认为价值仅在\"易理\"（哲学），否定\"象数/数术\"的科学性；  \\n另一派认为\"象数\"是易理的应用体现，两者不可割裂；  \\n折中观点主张\"学\"（理论）与\"术\"（应用）结合，古为今用。  \\n作者立场：支持第三种观点，强调象、数、理、占是统一整体，易学价值需从理论和应用两方面综合研究。  \\n4. 易学的科学定位  \\n思维科学为核心：作者引用钱学森的现代科学体系分类，提出易学应归入思维科学，因其提供了独特的认知模式（如辩证、象数思维），对自然科学、社会科学及人生实践均有指导意义。  \\n实践价值：易学不仅包含哲学思想（基础科学层次），也通过数术技术（工程技术层次）联系实际，促进物质与精神文明发展。  \\n5. 结论  \\n易学作为中华文化的智慧总汇，其核心价值在于思维科学领域，兼具理论深度与实践意义，需以开放态度继承发展，服务于现代科学与文明建设。  \\n第二章  \\n人脑思维方式与易学的产生  \\n1. 人类思维方式的分类  \\n现代思维科学将人类思维方式分为三类：  \\n逻辑思维（理性思维）：代表学科如数学、物理、化学。  \\n形象思维（感性思维）：代表学科如文学、艺术、音乐。  \\n灵感思维（感应思维/直觉思维）：代表学科如易学、佛学、心理学、气功。  \\n人类思维发展的规律：  \\n婴幼儿以感性思维为主，随着年龄增长，逻辑思维逐渐增强。']\n",
      "Answer: 根据提供的文件，《神奇之门: 奇门遁甲大解谜》一书提到了中国古代智慧，特别是易学，与现代科学思想的关联。具体来说：\n",
      "\n",
      "*   **易学的科学定位：** 作者认为易学应归入思维科学，因为它提供了一种独特的认知模式，如辩证、象数思维，对自然科学、社会科学及人生实践均有指导意义。\n",
      "\n",
      "*   **思维方式的分类：** 现代思维科学将人类思维方式分为逻辑思维、形象思维和灵感思维。易学被归类为灵感思维的代表学科之一。\n",
      "\n",
      "*   **易学的现代研究：** 近代以来，易学走向世界，引发跨学科研究热潮，包括社会科学、自然科学的多元视角。中外学者高度评价《周易》的智慧价值，认为其宇宙观与规律性研究对现代科学（如量子物理）有启发。\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAG instance\n",
    "rag = RAG()\n",
    "\n",
    "# Load documents\n",
    "rag.load_documents(docs)\n",
    "\n",
    "# Query and retrieve the most relevant document\n",
    "query = \"中国古代智慧，特别是易学，与现代科学思想有何关联？以具体的例子来证明这种关联。\"\n",
    "relevant_doc = rag.get_most_relevant_docs(query)\n",
    "\n",
    "# Generate an answer\n",
    "answer = rag.generate_answer(query, relevant_doc)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Relevant Document: {relevant_doc}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f2ef53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(features=['user_input', 'retrieved_contexts', 'reference_contexts', 'response', 'reference'], len=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ragas.dataset_schema import EvaluationDataset\n",
    "\n",
    "df = pd.read_parquet(\"data/ragas_openai_testset.parquet\")\n",
    "df[\"retrieved_contexts\"] = df[\"reference_contexts\"]\n",
    "df[\"response\"] = df[\"reference\"]\n",
    "data_list = df.to_dict(orient=\"records\")\n",
    "evaluation_dataset = EvaluationDataset.from_list(data_list)\n",
    "evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "783564a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  43%|████▎     | 13/30 [01:12<00:48,  2.85s/it]Exception raised in Job[19]: RateLimitError(Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '18s'}]}}])\n",
      "Evaluating:  67%|██████▋   | 20/30 [02:12<00:32,  3.29s/it]Exception raised in Job[2]: RateLimitError(Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}])\n",
      "Evaluating:  73%|███████▎  | 22/30 [02:17<00:23,  2.96s/it]Exception raised in Job[10]: TimeoutError()\n",
      "Evaluating:  77%|███████▋  | 23/30 [03:00<01:42, 14.68s/it]Exception raised in Job[13]: TimeoutError()\n",
      "Evaluating:  83%|████████▎ | 25/30 [03:03<00:43,  8.69s/it]Exception raised in Job[16]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 30/30 [03:58<00:00,  7.96s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 1.0000, 'faithfulness': 0.9444, 'factual_correctness(mode=f1)': 1.0000}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(rag.llm)\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,\n",
    "                  metrics=[\n",
    "                    LLMContextRecall(), \n",
    "                    Faithfulness(), \n",
    "                    FactualCorrectness()],\n",
    "                  llm=evaluator_llm\n",
    "                )\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c09acf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
